{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Title(TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nicolas Colebank\n",
    "- Andrew Consiglio\n",
    "- Cristina De La Torre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a relationship between past extreme weather events such as **[insert specifc weather used]** from 2018-2023, recent climate opinions from 2023, and policy **[are we still keeping this?]**  across states in the United States? Does this relationship vary in regards to state?\n",
    "<br><br>\n",
    "\n",
    "We define climate opinion to be based upon the responses of adults to the following questions: \n",
    "- Is global warming is affecting the weather? \n",
    "- Are you worried about global warming?\n",
    "- Do you support regulating CO2 as a pollutant?\n",
    "- Should global warming be a priority for the next president and Congress?\n",
    "- Do you discuss global warming at least occasionally? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why is this problem relevant? Or, what inspired you to investigate this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global warming and the effects of environmental issues at large remain relevant especially with recent patterns of natural disasters and climate change in the United States. Yet, developing effective ways with which to address the impacts of these issues remain challenging at a national scale. We want to assess this challenge by investigating possible factors that may explain the difficulty in addressing environmental issues across the country. More specifically we will be investigating these factors in relation to local extreme weather events.\n",
    "\n",
    " The complexity of this problem may be shaped by polarized public perception and local experiences, and so the factors we will assess will focus on local sentiment and socioeconomic elements. Analyzing sentiment such as beliefs, risk perceptions, policy support, and behaviors at a local level might lead to a richer understanding of diverse opinions. To develop larger contextual comprehension, analyzing trends of local natural disasters and environmental issues like fracking and pollution may be useful along with an investigation of local governments, their policies, and access to resources.\n",
    " \n",
    "It is through an analysis of extreme weather and these factors that we would like to work towards developing effective ways to address the impact of climate change at the federal level. Hence, exploring the relationship between severe weather, public opinion, and socioeconomic disparities is particularly important because it can provide a contextual framework with which to tackle the challenge of developing effective solutions to mitigate the effects of environmental issues. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist a relationship between recent climate opinions and extreme weather events such that as the frequency of extreme weather events increases so does negative opinions on climate.\n",
    "\n",
    "(TO DO Rationale) This is due to previously mentioned study in which __ . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data(WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Where did you get the data from?<br>\n",
    ">Description of the data\n",
    "\n",
    "There are a few datasets that would prove useful for making a statistical analysis to help answer this problem. For one, Yale has a dataset containing climate opinion data in the U.S. down to the county, where respondents were asked questions such as “Is climate change happening?” or questions about who should act and what policies should be implemented to affect global warming. Additionally, the National Oceanic and Atmospheric Administration (NOAA) has data on extreme weather events throughout the U.S., dating back to 1950. Harvard’s county-level dataset on U.S. Senate voting can be used to see how partisan voting influences climate change as well. All of these datasets can be downloaded as CSV files. We will use python’s pandas library to merge these datasets together, which can be done by using county name + state, which when combined is always a unique identifier. For the dataset on extreme weather events, the data can only be downloaded by type of weather event. We will pick the most common extreme weather events and use these in our main dataset.\n",
    "\n",
    "\n",
    "- Yale dataset:\n",
    "    - sample size>31000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Opinion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geotype</th>\n",
       "      <th>geoid</th>\n",
       "      <th>geoname</th>\n",
       "      <th>varname</th>\n",
       "      <th>x2010</th>\n",
       "      <th>x2011</th>\n",
       "      <th>x2012</th>\n",
       "      <th>x2013</th>\n",
       "      <th>x2014</th>\n",
       "      <th>x2015</th>\n",
       "      <th>x2016</th>\n",
       "      <th>x2017</th>\n",
       "      <th>x2018</th>\n",
       "      <th>x2019</th>\n",
       "      <th>x2020</th>\n",
       "      <th>x2021</th>\n",
       "      <th>x2022</th>\n",
       "      <th>x2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.66</td>\n",
       "      <td>49.22</td>\n",
       "      <td>53.33</td>\n",
       "      <td>53.64</td>\n",
       "      <td>49.63</td>\n",
       "      <td>50.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state</td>\n",
       "      <td>2</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.48</td>\n",
       "      <td>54.94</td>\n",
       "      <td>60.92</td>\n",
       "      <td>62.25</td>\n",
       "      <td>59.17</td>\n",
       "      <td>60.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>state</td>\n",
       "      <td>4</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.32</td>\n",
       "      <td>58.40</td>\n",
       "      <td>63.55</td>\n",
       "      <td>64.22</td>\n",
       "      <td>61.73</td>\n",
       "      <td>63.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>5</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.17</td>\n",
       "      <td>50.78</td>\n",
       "      <td>55.72</td>\n",
       "      <td>55.89</td>\n",
       "      <td>51.26</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state</td>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.21</td>\n",
       "      <td>64.51</td>\n",
       "      <td>69.28</td>\n",
       "      <td>70.14</td>\n",
       "      <td>67.47</td>\n",
       "      <td>68.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geotype  geoid     geoname        varname  x2010  x2011  x2012  x2013  \\\n",
       "0   state      1     Alabama  affectweather    NaN    NaN    NaN    NaN   \n",
       "1   state      2      Alaska  affectweather    NaN    NaN    NaN    NaN   \n",
       "2   state      4     Arizona  affectweather    NaN    NaN    NaN    NaN   \n",
       "3   state      5    Arkansas  affectweather    NaN    NaN    NaN    NaN   \n",
       "4   state      6  California  affectweather    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   x2014  x2015  x2016  x2017  x2018  x2019  x2020  x2021  x2022  x2023  \n",
       "0    NaN    NaN    NaN    NaN  52.66  49.22  53.33  53.64  49.63  50.28  \n",
       "1    NaN    NaN    NaN    NaN  57.48  54.94  60.92  62.25  59.17  60.66  \n",
       "2    NaN    NaN    NaN    NaN  60.32  58.40  63.55  64.22  61.73  63.12  \n",
       "3    NaN    NaN    NaN    NaN  53.17  50.78  55.72  55.89  51.26  52.43  \n",
       "4    NaN    NaN    NaN    NaN  67.21  64.51  69.28  70.14  67.47  68.39  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yale_climate = pd.read_csv('data/yale_climate.csv')\n",
    "yale_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoname</th>\n",
       "      <th>varname</th>\n",
       "      <th>x2018</th>\n",
       "      <th>x2019</th>\n",
       "      <th>x2020</th>\n",
       "      <th>x2021</th>\n",
       "      <th>x2022</th>\n",
       "      <th>x2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>52.66</td>\n",
       "      <td>49.22</td>\n",
       "      <td>53.33</td>\n",
       "      <td>53.64</td>\n",
       "      <td>49.63</td>\n",
       "      <td>50.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>57.48</td>\n",
       "      <td>54.94</td>\n",
       "      <td>60.92</td>\n",
       "      <td>62.25</td>\n",
       "      <td>59.17</td>\n",
       "      <td>60.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>60.32</td>\n",
       "      <td>58.40</td>\n",
       "      <td>63.55</td>\n",
       "      <td>64.22</td>\n",
       "      <td>61.73</td>\n",
       "      <td>63.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>53.17</td>\n",
       "      <td>50.78</td>\n",
       "      <td>55.72</td>\n",
       "      <td>55.89</td>\n",
       "      <td>51.26</td>\n",
       "      <td>52.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>67.21</td>\n",
       "      <td>64.51</td>\n",
       "      <td>69.28</td>\n",
       "      <td>70.14</td>\n",
       "      <td>67.47</td>\n",
       "      <td>68.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoname        varname  x2018  x2019  x2020  x2021  x2022  x2023\n",
       "0     ALABAMA  affectweather  52.66  49.22  53.33  53.64  49.63  50.28\n",
       "1      ALASKA  affectweather  57.48  54.94  60.92  62.25  59.17  60.66\n",
       "2     ARIZONA  affectweather  60.32  58.40  63.55  64.22  61.73  63.12\n",
       "3    ARKANSAS  affectweather  53.17  50.78  55.72  55.89  51.26  52.43\n",
       "4  CALIFORNIA  affectweather  67.21  64.51  69.28  70.14  67.47  68.39"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yale_climate = yale_climate[yale_climate['geotype'] == 'state']\n",
    "yale_climate = yale_climate[['geoname','varname', 'x2018', 'x2019', 'x2020', 'x2021', 'x2022', 'x2023']]\n",
    "\n",
    "#consistent state names across both datasets\n",
    "yale_climate['geoname'] = yale_climate['geoname'].str.upper() \n",
    "yale_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoname</th>\n",
       "      <th>varname</th>\n",
       "      <th>year</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>2018</td>\n",
       "      <td>52.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>2018</td>\n",
       "      <td>57.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>2018</td>\n",
       "      <td>60.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>2018</td>\n",
       "      <td>53.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>affectweather</td>\n",
       "      <td>2018</td>\n",
       "      <td>67.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoname        varname  year  percentage\n",
       "0     ALABAMA  affectweather  2018       52.66\n",
       "1      ALASKA  affectweather  2018       57.48\n",
       "2     ARIZONA  affectweather  2018       60.32\n",
       "3    ARKANSAS  affectweather  2018       53.17\n",
       "4  CALIFORNIA  affectweather  2018       67.21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted = pd.melt(yale_climate, id_vars=['geoname', 'varname'], var_name='year', value_name='percentage')\n",
    "melted['year'] = melted['year'].str.replace('x','').astype(int)\n",
    "yale_climate = melted\n",
    "yale_climate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202310</td>\n",
       "      <td>25</td>\n",
       "      <td>230</td>\n",
       "      <td>202310</td>\n",
       "      <td>27</td>\n",
       "      <td>551</td>\n",
       "      <td>186682</td>\n",
       "      <td>1145781</td>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In late October, a winter storm dumped heavy s...</td>\n",
       "      <td>Public reports 7.5 inches at Black Tiger Bay C...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202310</td>\n",
       "      <td>25</td>\n",
       "      <td>230</td>\n",
       "      <td>202310</td>\n",
       "      <td>27</td>\n",
       "      <td>1437</td>\n",
       "      <td>186682</td>\n",
       "      <td>1145783</td>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In late October, a winter storm dumped heavy s...</td>\n",
       "      <td>Local Police Department relays storm total sno...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202310</td>\n",
       "      <td>25</td>\n",
       "      <td>230</td>\n",
       "      <td>202310</td>\n",
       "      <td>27</td>\n",
       "      <td>1126</td>\n",
       "      <td>186682</td>\n",
       "      <td>1145784</td>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In late October, a winter storm dumped heavy s...</td>\n",
       "      <td>Public reports 10 inches of storm total snowfa...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202310</td>\n",
       "      <td>25</td>\n",
       "      <td>230</td>\n",
       "      <td>202310</td>\n",
       "      <td>27</td>\n",
       "      <td>1301</td>\n",
       "      <td>186682</td>\n",
       "      <td>1145796</td>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In late October, a winter storm dumped heavy s...</td>\n",
       "      <td>Emergency Manager reports 6 inches of storm to...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202310</td>\n",
       "      <td>25</td>\n",
       "      <td>230</td>\n",
       "      <td>202310</td>\n",
       "      <td>27</td>\n",
       "      <td>600</td>\n",
       "      <td>186682</td>\n",
       "      <td>1145884</td>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In late October, a winter storm dumped heavy s...</td>\n",
       "      <td>CoCoRaHS Station ND-GF-23 reports 8.8 inches o...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           202310         25         230         202310       27       551   \n",
       "1           202310         25         230         202310       27      1437   \n",
       "2           202310         25         230         202310       27      1126   \n",
       "3           202310         25         230         202310       27      1301   \n",
       "4           202310         25         230         202310       27       600   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID         STATE  STATE_FIPS  ...  END_RANGE END_AZIMUTH  \\\n",
       "0      186682   1145781  NORTH DAKOTA          38  ...        NaN         NaN   \n",
       "1      186682   1145783  NORTH DAKOTA          38  ...        NaN         NaN   \n",
       "2      186682   1145784  NORTH DAKOTA          38  ...        NaN         NaN   \n",
       "3      186682   1145796  NORTH DAKOTA          38  ...        NaN         NaN   \n",
       "4      186682   1145884  NORTH DAKOTA          38  ...        NaN         NaN   \n",
       "\n",
       "  END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT END_LON  \\\n",
       "0          NaN       NaN        NaN     NaN     NaN   \n",
       "1          NaN       NaN        NaN     NaN     NaN   \n",
       "2          NaN       NaN        NaN     NaN     NaN   \n",
       "3          NaN       NaN        NaN     NaN     NaN   \n",
       "4          NaN       NaN        NaN     NaN     NaN   \n",
       "\n",
       "                                   EPISODE_NARRATIVE  \\\n",
       "0  In late October, a winter storm dumped heavy s...   \n",
       "1  In late October, a winter storm dumped heavy s...   \n",
       "2  In late October, a winter storm dumped heavy s...   \n",
       "3  In late October, a winter storm dumped heavy s...   \n",
       "4  In late October, a winter storm dumped heavy s...   \n",
       "\n",
       "                                     EVENT_NARRATIVE DATA_SOURCE  \n",
       "0  Public reports 7.5 inches at Black Tiger Bay C...         CSV  \n",
       "1  Local Police Department relays storm total sno...         CSV  \n",
       "2  Public reports 10 inches of storm total snowfa...         CSV  \n",
       "3  Emergency Manager reports 6 inches of storm to...         CSV  \n",
       "4  CoCoRaHS Station ND-GF-23 reports 8.8 inches o...         CSV  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/storm_dataset2023.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>Heavy Snow</td>\n",
       "      <td>2023</td>\n",
       "      <td>186682</td>\n",
       "      <td>In late October, a winter storm dumped heavy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>2023</td>\n",
       "      <td>180848</td>\n",
       "      <td>In the afternoon and evening of the 24th, clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>Drought</td>\n",
       "      <td>2023</td>\n",
       "      <td>186724</td>\n",
       "      <td>D2 Drought continued from September into early...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>2023</td>\n",
       "      <td>184619</td>\n",
       "      <td>A vigorous short-wave trough interacted with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>2023</td>\n",
       "      <td>185704</td>\n",
       "      <td>Scattered severe thunderstorms in advance of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74851</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>2023</td>\n",
       "      <td>186385</td>\n",
       "      <td>Thunderstorms developed along a cold front as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74858</th>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>Flash Flood</td>\n",
       "      <td>2023</td>\n",
       "      <td>184741</td>\n",
       "      <td>An area of low pressure moved northeast from M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74863</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>2023</td>\n",
       "      <td>185514</td>\n",
       "      <td>While weather conditions were pretty tame, we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74864</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>2023</td>\n",
       "      <td>185515</td>\n",
       "      <td>Hot conditions continued for the eastern Panha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74898</th>\n",
       "      <td>WYOMING</td>\n",
       "      <td>Hail</td>\n",
       "      <td>2023</td>\n",
       "      <td>184461</td>\n",
       "      <td>An isolated thunderstorm produced quarter size...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               STATE         EVENT_TYPE  YEAR  EPISODE_ID  \\\n",
       "0       NORTH DAKOTA         Heavy Snow  2023      186682   \n",
       "6        MISSISSIPPI  Thunderstorm Wind  2023      180848   \n",
       "7          MINNESOTA            Drought  2023      186724   \n",
       "9           ILLINOIS  Thunderstorm Wind  2023      184619   \n",
       "11          VIRGINIA  Thunderstorm Wind  2023      185704   \n",
       "...              ...                ...   ...         ...   \n",
       "74851          TEXAS  Thunderstorm Wind  2023      186385   \n",
       "74858  NEW HAMPSHIRE        Flash Flood  2023      184741   \n",
       "74863          TEXAS           Wildfire  2023      185514   \n",
       "74864          TEXAS           Wildfire  2023      185515   \n",
       "74898        WYOMING               Hail  2023      184461   \n",
       "\n",
       "                                       EPISODE_NARRATIVE  \n",
       "0      In late October, a winter storm dumped heavy s...  \n",
       "6      In the afternoon and evening of the 24th, clus...  \n",
       "7      D2 Drought continued from September into early...  \n",
       "9      A vigorous short-wave trough interacted with a...  \n",
       "11     Scattered severe thunderstorms in advance of a...  \n",
       "...                                                  ...  \n",
       "74851  Thunderstorms developed along a cold front as ...  \n",
       "74858  An area of low pressure moved northeast from M...  \n",
       "74863  While weather conditions were pretty tame, we ...  \n",
       "74864  Hot conditions continued for the eastern Panha...  \n",
       "74898  An isolated thunderstorm produced quarter size...  \n",
       "\n",
       "[10283 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are multiple events for the same episode, this removes them\n",
    "unique = df.drop_duplicates(subset=['STATE_FIPS', 'EPISODE_ID']) \n",
    "agg_funcs = {\n",
    "    'EVENT_ID': 'count',\n",
    "    'YEAR': 'first',\n",
    "}\n",
    "\n",
    "by_state = unique.groupby('STATE').agg(agg_funcs).reset_index()\n",
    "by_state = by_state.rename({'EVENT_ID': 'COUNT'}, axis=1)\n",
    "\n",
    "#only columns we might use\n",
    "events = unique[['STATE', 'EVENT_TYPE', 'YEAR', 'EPISODE_ID', 'EPISODE_NARRATIVE']] \n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dfs = []\n",
    "by_state_dfs = []\n",
    "def load_storm(year):\n",
    "    df = pd.read_csv(f'data/storm_dataset{year}.csv')\n",
    "    unique = df.drop_duplicates(subset=['STATE_FIPS', 'EPISODE_ID']) #there are multiple events for the same episode, this removes them\n",
    "    agg_funcs = {\n",
    "        'EVENT_ID': 'count',\n",
    "        'YEAR': 'first',\n",
    "    }\n",
    "    by_state = unique.groupby('STATE').agg(agg_funcs).reset_index()\n",
    "    by_state = by_state.rename({'EVENT_ID': 'COUNT'}, axis=1)\n",
    "    events = unique[['STATE', 'EVENT_TYPE', 'YEAR', 'EPISODE_ID', 'EPISODE_NARRATIVE']] #only columns we might use\n",
    "    event_dfs.append(events)\n",
    "    by_state_dfs.append(by_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2018 + i for i in range(6)]\n",
    "for year in years:\n",
    "    load_storm(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>149</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>68</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMERICAN SAMOA</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>277</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>191</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>212</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>107</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>WEST VIRGINIA</td>\n",
       "      <td>131</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>211</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WYOMING</td>\n",
       "      <td>235</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             STATE  COUNT  YEAR\n",
       "0          ALABAMA    149  2018\n",
       "1           ALASKA     68  2018\n",
       "2   AMERICAN SAMOA     19  2018\n",
       "3          ARIZONA    277  2018\n",
       "4         ARKANSAS    191  2018\n",
       "..             ...    ...   ...\n",
       "62        VIRGINIA    212  2023\n",
       "63      WASHINGTON    107  2023\n",
       "64   WEST VIRGINIA    131  2023\n",
       "65       WISCONSIN    211  2023\n",
       "66         WYOMING    235  2023\n",
       "\n",
       "[399 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note: some 'states' on here are not actual states (like Lake Superior) - we will ignore these for now\n",
    "events_df = pd.concat(event_dfs, axis=0)\n",
    "event_count_df = pd.concat(by_state_dfs, axis=0)\n",
    "event_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df_merged = events_df.merge(yale_climate, how='inner', left_on=['STATE', 'YEAR'], right_on=['geoname','year'])\n",
    "\n",
    "#data for each event type along with yale climate data\n",
    "events_df_merged = events_df_merged.drop(columns=['geoname', 'year']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_count_merged = event_count_df.merge(yale_climate, how='inner', left_on=['STATE', 'YEAR'], right_on=['geoname', 'year'])\n",
    "\n",
    "#data with number of events for each year along with the yale climate data\n",
    "event_count_merged = event_count_merged.drop(columns=['geoname', 'year']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO identify questions and filter dfs for each question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What (if any) analyses have already been performed on this data (or another similar dataset)?<br>\n",
    "> You should provide references to this<br>\n",
    "> What types of analyses did you perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How do you interpret the results from these analyses?\n",
    "> What are some potential limitations and shortcoming of your analyses?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "42280026aa18012503da8cb6da489570981d61455d528b8c180c8362ab4390e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
